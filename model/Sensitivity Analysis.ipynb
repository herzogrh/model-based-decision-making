{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the problem and policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, perform_experiments, ema_logging, Policy, Scenario)\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS\n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging, save_results, load_results\n",
    "from specify import specify_levers\n",
    "\n",
    "\n",
    "from SALib.analyze import sobol\n",
    "from plotting_for_sobol import plot_sobol_indices, plot_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specification of the problem\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(1)\n",
    "\n",
    "#Specification of the policies\n",
    "\n",
    "n_policies = 4\n",
    "policy0 = Policy('policy_0', **{'0_RfR 0': 0, '0_RfR 1' : 0, '0_RfR 2' : 0,\n",
    "                    '1_RfR 0': 0, '1_RfR 1' : 0, '1_RfR 2' : 0,\n",
    "                    '2_RfR 0': 0, '2_RfR 1' : 0, '2_RfR 2' : 0,\n",
    "                    '3_RfR 0': 0, '3_RfR 1' : 0, '3_RfR 2' : 0,\n",
    "                    '4_RfR 0': 0, '4_RfR 1' : 0, '4_RfR 2' : 0,\n",
    "                    'A.1_DikeIncrease 0' : 0, 'A.1_DikeIncrease 1' : 0, 'A.1_DikeIncrease 2' : 0,\n",
    "                    'A.2_DikeIncrease 0' : 0, 'A.2_DikeIncrease 1' : 0, 'A.2_DikeIncrease 2' : 0,\n",
    "                    'A.3_DikeIncrease 0' : 0, 'A.3_DikeIncrease 1' : 0, 'A.3_DikeIncrease 2' : 0,\n",
    "                    'A.4_DikeIncrease 0' : 0, 'A.4_DikeIncrease 1' : 0, 'A.4_DikeIncrease 2' : 0,\n",
    "                    'A.5_DikeIncrease 0' : 0, 'A.5_DikeIncrease 1' : 0, 'A.5_DikeIncrease 2' : 0,\n",
    "                    'EWS_DaysToThreat':  0   }) # DO NOTHING\n",
    "policy1 = Policy('policy_1', **{'0_RfR 0': 0, '0_RfR 1' : 0, '0_RfR 2' : 0,\n",
    "                    '1_RfR 0': 0, '1_RfR 1' : 0, '1_RfR 2' : 0,\n",
    "                    '2_RfR 0': 0, '2_RfR 1' : 0, '2_RfR 2' : 0,\n",
    "                    '3_RfR 0': 0, '3_RfR 1' : 0, '3_RfR 2' : 0,\n",
    "                    '4_RfR 0': 0, '4_RfR 1' : 0, '4_RfR 2' : 0,\n",
    "                    'A.1_DikeIncrease 0' : 10, 'A.1_DikeIncrease 1' : 0, 'A.1_DikeIncrease 2' : 0,\n",
    "                    'A.2_DikeIncrease 0' : 0, 'A.2_DikeIncrease 1' : 0, 'A.2_DikeIncrease 2' : 0,\n",
    "                    'A.3_DikeIncrease 0' : 10, 'A.3_DikeIncrease 1' : 0, 'A.3_DikeIncrease 2' : 0,\n",
    "                    'A.4_DikeIncrease 0' : 0, 'A.4_DikeIncrease 1' : 0, 'A.4_DikeIncrease 2' : 0,\n",
    "                    'A.5_DikeIncrease 0' : 0, 'A.5_DikeIncrease 1' : 0, 'A.5_DikeIncrease 2' : 0,\n",
    "                    'EWS_DaysToThreat':  0   }) # DO DIKES at A1, A3\n",
    "policy2 = Policy('policy_2', **{'0_RfR 0': 0, '0_RfR 1' : 0, '0_RfR 2' : 0,\n",
    "                    '1_RfR 0': 0, '1_RfR 1' : 0, '1_RfR 2' : 0,\n",
    "                    '2_RfR 0': 0, '2_RfR 1' : 0, '2_RfR 2' : 0,\n",
    "                    '3_RfR 0': 0, '3_RfR 1' : 0, '3_RfR 2' : 0,\n",
    "                    '4_RfR 0': 0, '4_RfR 1' : 0, '4_RfR 2' : 0,\n",
    "                    'A.1_DikeIncrease 0' : 10, 'A.1_DikeIncrease 1' : 0, 'A.1_DikeIncrease 2' : 0,\n",
    "                    'A.2_DikeIncrease 0' : 10, 'A.2_DikeIncrease 1' : 0, 'A.2_DikeIncrease 2' : 0,\n",
    "                    'A.3_DikeIncrease 0' : 10, 'A.3_DikeIncrease 1' : 0, 'A.3_DikeIncrease 2' : 0,\n",
    "                    'A.4_DikeIncrease 0' : 0, 'A.4_DikeIncrease 1' : 0, 'A.4_DikeIncrease 2' : 0,\n",
    "                    'A.5_DikeIncrease 0' : 10, 'A.5_DikeIncrease 1' : 0, 'A.5_DikeIncrease 2' : 0,\n",
    "                    'EWS_DaysToThreat':  0   }) # DO DIKES at A1, A2, A3, A5\n",
    "policy3 = Policy('policy_3', **{'0_RfR 0': 0, '0_RfR 1' : 0, '0_RfR 2' : 0,\n",
    "                    '1_RfR 0': 1, '1_RfR 1' : 0, '1_RfR 2' : 0,\n",
    "                    '2_RfR 0': 1, '2_RfR 1' : 0, '2_RfR 2' : 0,\n",
    "                    '3_RfR 0': 1, '3_RfR 1' : 0, '3_RfR 2' : 0,\n",
    "                    '4_RfR 0': 1, '4_RfR 1' : 0, '4_RfR 2' : 0,\n",
    "                    'A.1_DikeIncrease 0' : 10, 'A.1_DikeIncrease 1' : 0, 'A.1_DikeIncrease 2' : 0,\n",
    "                    'A.2_DikeIncrease 0' : 10, 'A.2_DikeIncrease 1' : 0, 'A.2_DikeIncrease 2' : 0,\n",
    "                    'A.3_DikeIncrease 0' : 10, 'A.3_DikeIncrease 1' : 0, 'A.3_DikeIncrease 2' : 0,\n",
    "                    'A.4_DikeIncrease 0' : 10, 'A.4_DikeIncrease 1' : 0, 'A.4_DikeIncrease 2' : 0,\n",
    "                    'A.5_DikeIncrease 0' : 10, 'A.5_DikeIncrease 1' : 0, 'A.5_DikeIncrease 2' : 0,\n",
    "                    'EWS_DaysToThreat':  4   }) # DO EVERYTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sobol's scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Execute Sensistivity Analysis on uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a total of N(2K+2) = 5(2\\*19+2) experiments, since the dike model has K=19 uncertainties and we use a baseline number of experiments equalling N=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dike_model.uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the problem into an SA-equivalent problem\n",
    "\n",
    "sa_problem = get_SALib_problem(dike_model.uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 200 scenarios * 4 policies * 1 model(s) = 800 experiments\n",
      "[MainProcess/INFO] 80 cases completed\n",
      "[MainProcess/INFO] 160 cases completed\n",
      "[MainProcess/INFO] 240 cases completed\n",
      "[MainProcess/INFO] 320 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 480 cases completed\n",
      "[MainProcess/INFO] 560 cases completed\n",
      "[MainProcess/INFO] 640 cases completed\n",
      "[MainProcess/INFO] 720 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sobol time is 13 minutes\n"
     ]
    }
   ],
   "source": [
    "# Execute Sensistivity Analysis over uncertainties\n",
    "\n",
    "baseline_n_experiments_u = 5\n",
    "start = time.time()\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "     experiments, outcomes = evaluator.perform_experiments(scenarios = baseline_n_experiments_u,\n",
    "                                                           policies = [policy0, policy1, policy2, policy3], \n",
    "                                                           uncertainty_sampling = SOBOL)\n",
    "end = time.time()\n",
    "print('Sobol time is ' + str(round((end - start)/60)) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results saved successfully to C:\\Users\\frac1\\Documents\\GitHub\\Model Based DM - Assignment collaboration\\model-based-decision-making\\results\\Sensitivity_5ex_over_uncertainties_200s_4pol.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# save the results\n",
    "\n",
    "u_results = (experiments, outcomes)\n",
    "save_results(u_results, \"../results/Sensitivity_\"+str(baseline_n_experiments_u)+\"ex_over_uncertainties_200s_4pol.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] results loaded succesfully from C:\\Users\\frac1\\Documents\\GitHub\\Model Based DM - Assignment collaboration\\model-based-decision-making\\results\\Sensitivity_5ex_over_uncertainties_200s_4pol.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# load the results\n",
    "\n",
    "experiments, outcomes = load_results(\"../results/Sensitivity_\"+str(baseline_n_experiments_u)+\"ex_over_uncertainties_200s_4pol.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Execute Sensistivity Analysis on levers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a sensitivity analysis over a total of N(2K+2) = 1(2\\*31+2) experiments, since the dike model has K=31 levers and we use a baseline number of experiments equalling N=1 under the reference scenario (set as the worst-case scenario, and found from the notebook 1 - Reference Case Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dike_model.levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the problem into an SA-equivalent problem\n",
    "\n",
    "sa_problem = get_SALib_problem(dike_model.levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load policy results of a NoAction policy under 500 scenarios (notebook 1-Reference Case Scenario)\n",
    "[experiments, outcomes] = load_results(\"../results/500Scenarios_NoAction_PF1.tar.gz\")\n",
    "outcomes_df = pd.DataFrame(data=outcomes)\n",
    "\n",
    "#Get index of worst-case scenario\n",
    "index_wc = outcomes_df.sort_values(\"Expected Number of Deaths\").tail(1).index\n",
    "experiment_wc = experiments.iloc[index_wc]\n",
    "\n",
    "#Set the reference scenario as the worst-case scenario\n",
    "reference_scenarios = [Scenario(f\"{index}\", **row) for index, row in experiment_wc.iloc[0:,0:19].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Sensistivity Analysis over levers\n",
    "\n",
    "baseline_n_experiments_l = 1\n",
    "\n",
    "start = time.time()\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "     experiments, outcomes = evaluator.perform_experiments(scenarios = reference_scenarios,\n",
    "                                                           policies = baseline_n_experiments_l,\n",
    "                                                           levers_sampling = SOBOL)\n",
    "end = time.time()\n",
    "print('Sobol time is ' + str(round((end - start)/60)) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results\n",
    "\n",
    "l_results = (experiments, outcomes)\n",
    "save_results(l_results,  \"../results/Sensitivity_\"+str(baseline_n_experiments_l)+\"ex_over_levers_RefScenario.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the levers' results\n",
    "\n",
    "#experiments, outcomes = load_results(\"../results/Sensitivity_\"+str(baseline_n_experiments_l)+\"ex_over_levers_RefScenario.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate Sobol's scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 53)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(experiments).shape[0] #tells the number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be done for uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = baseline_n_experiments_u #baseline_n_experiments for uncertainties\n",
    "K = len(dike_model.uncertainties) #number of uncertainties\n",
    "sobol_multiplier = 2*K+2\n",
    "\n",
    "\n",
    "\n",
    "policies = np.empty([len(experiments), 1])\n",
    "k = 0\n",
    "l = N*sobol_multiplier\n",
    "for i in range (len(experiments)) : \n",
    "    policies[i] = k\n",
    "    if (i == l - 1) : \n",
    "        k = k + 1\n",
    "        l = l + n_scenarios * sobol_multiplier\n",
    "policies = policies.astype(int)\n",
    "\n",
    "data = pd.DataFrame.from_dict(outcomes)\n",
    "data['Policy'] = policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "795    1\n",
       "796    1\n",
       "797    1\n",
       "798    1\n",
       "799    1\n",
       "Name: Policy, Length: 800, dtype: int32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Policy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of S1, S2, ST indices\n",
    "\n",
    "problem = get_SALib_problem(dike_model.levers)\n",
    "scores = []\n",
    "for i in range(0, 1) : \n",
    "    scores.append(sobol.analyze(problem, outcomes_tup[0][:, i], calc_second_order=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_scores(scores[0], problem)\n",
    "for i in range(1, 1) : \n",
    "    figi = plot_scores(scores[i], problem)\n",
    "    figi.axes.append(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.set_size_inches(7,7)\n",
    "\n",
    "figi = plot_sobol_indices(scores[0], problem, criterion='ST', threshold=0.005)\n",
    "figi.set_size_inches(7,7)\n",
    "figi.axes.append(fig)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondac1b64f39f6da43e88cff8fe3098785bd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
